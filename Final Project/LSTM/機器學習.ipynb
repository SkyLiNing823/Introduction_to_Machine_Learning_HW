{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://iter01.com/418571.html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from itertools import accumulate\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    296\n",
      "1    301\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('data.xlsx')\n",
    "df.head()\n",
    "print(df.groupby('label')['label'].count()) #0代表負面，1代表正面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, input_shape=20):\n",
    "    df = pd.read_excel(filepath)\n",
    "\n",
    "    # 標籤及詞彙表\n",
    "    labels, vocabulary = list(df['label'].unique()), list(df['comment'].unique())\n",
    "\n",
    "    # 構造字元級別的特徵\n",
    "    string = ''\n",
    "    for word in vocabulary:\n",
    "        string += word\n",
    "\n",
    "    vocabulary = set(string)\n",
    "\n",
    "    # 字典列表\n",
    "    word_dictionary = {word: i+1 for i, word in enumerate(vocabulary)}\n",
    "    with open('word_dict.pk', 'wb') as f:\n",
    "        pickle.dump(word_dictionary, f)\n",
    "    inverse_word_dictionary = {i+1: word for i, word in enumerate(vocabulary)}\n",
    "    label_dictionary = {label: i for i, label in enumerate(labels)}\n",
    "    with open('label_dict.pk', 'wb') as f:\n",
    "        pickle.dump(label_dictionary, f)\n",
    "    output_dictionary = {i: labels for i, labels in enumerate(labels)}\n",
    "\n",
    "    vocab_size = len(word_dictionary.keys()) # 詞彙表大小\n",
    "    label_size = len(label_dictionary.keys()) # 標籤類別數量\n",
    "\n",
    "    # 序列填充，按input_shape填充，長度不足的按0補充\n",
    "    x = [[word_dictionary[word] for word in sent] for sent in df['comment']]\n",
    "    x = pad_sequences(maxlen=input_shape, sequences=x, padding='post', value=0)\n",
    "    y = [[label_dictionary[sent]] for sent in df['label']]\n",
    "    y = [to_categorical(label, num_classes=label_size) for label in y]\n",
    "    y = np.array([list(_[0]) for _ in y])\n",
    "\n",
    "    return x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary\n",
    "\n",
    "# 建立深度學習模型\n",
    "def create_LSTM(n_units, input_shape, output_dim, filepath):\n",
    "    x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary = load_data(filepath)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size + 1, output_dim=output_dim,\n",
    "                        input_length=input_shape, mask_zero=True))\n",
    "    model.add(LSTM(n_units, input_shape=(x.shape[0], x.shape[1])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(label_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    plot_model(model, to_file='./model_lstm.png', show_shapes=True)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# 模型訓練\n",
    "def model_train(input_shape, filepath, model_save_path):\n",
    "\n",
    "    # 將資料集分為訓練集和測試集，佔比為9:1\n",
    "    # input_shape = 100\n",
    "    x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary = load_data(filepath, input_shape)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.1, random_state = 42)\n",
    "\n",
    "    # 模型輸入引數，需要自己根據需要調整\n",
    "    n_units = 100\n",
    "    batch_size = 32\n",
    "    epochs = 5\n",
    "    output_dim = 20\n",
    "\n",
    "    # 模型訓練\n",
    "    lstm_model = create_LSTM(n_units, input_shape, output_dim, filepath)\n",
    "    lstm_model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # 模型儲存\n",
    "    lstm_model.save(model_save_path)\n",
    "\n",
    "    N = test_x.shape[0]  # 測試的條數\n",
    "    predict = []\n",
    "    label = []\n",
    "    for start, end in zip(range(0, N, 1), range(1, N+1, 1)):\n",
    "        sentence = [inverse_word_dictionary[i] for i in test_x[start] if i != 0]\n",
    "        y_predict = lstm_model.predict(test_x[start:end])\n",
    "        label_predict = output_dictionary[np.argmax(y_predict[0])]\n",
    "        label_true = output_dictionary[np.argmax(test_y[start:end])]\n",
    "        print(''.join(sentence), label_true, label_predict) # 輸出預測結果\n",
    "        predict.append(label_predict)\n",
    "        label.append(label_true)\n",
    "\n",
    "    acc = accuracy_score(predict, label) # 預測準確率\n",
    "    print('模型在測試集上的準確率為: %s.' % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入語句: 我好開心\n",
      "情感預測結果: 1\n"
     ]
    }
   ],
   "source": [
    "# 匯入字典\n",
    "with open('word_dict.pk', 'rb') as f:\n",
    "    word_dictionary = pickle.load(f)\n",
    "with open('label_dict.pk', 'rb') as f:\n",
    "    output_dictionary = pickle.load(f)\n",
    "\n",
    "try:\n",
    "    # 資料預處理\n",
    "    input_shape = 180\n",
    "    sent = \"我好開心\"\n",
    "    x = [[word_dictionary[word] for word in sent]]\n",
    "    x = pad_sequences(maxlen=input_shape, sequences=x, padding='post', value=0)\n",
    "\n",
    "    # 載入模型\n",
    "    model_save_path = './corpus_model.h5'\n",
    "    lstm_model = load_model(model_save_path)\n",
    "\n",
    "    # 模型預測\n",
    "    y_predict = lstm_model.predict(x)\n",
    "    label_dict = {v:k for k,v in output_dictionary.items()}\n",
    "    print('輸入語句: %s' % sent)\n",
    "    print('情感預測結果: %s' % label_dict[np.argmax(y_predict)])\n",
    "\n",
    "except KeyError as err:\n",
    "    print(\"您輸入的句子有漢字不在詞彙表中，請重新輸入！\")\n",
    "    print(\"不在詞彙表中的單詞為：%s.\" % err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
